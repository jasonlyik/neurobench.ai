---
title: "Machine Learning Sensors"
layout: splash
permalink: 
date:
header:
  overlay_color: "#00A"
  overlay_filter: "0.5"
  overlay_image: /assets/images/banner.png
  actions:
    # - label: "To learn more about our approach, check out our whitepaper on arXiv"
    #   url: "https://arxiv.org/abs/2206.03266"
  caption: ""
excerpt: "An ML sensor is a self-contained system that utilizes on-device machine learning to extract useful information by observing some complex set of phenomena in the physical world and reports it through a simple interface to a wider system."

sponsors_intro: 
  - title: "Thanks to our lead supporters:"

challenges:
  - image_path: "/assets/images/thumbnails/interface.png"
    alt: "Interface"
    title: "Interface"
    excerpt: "What universal interface is needed for ML Sensors?"

  - image_path: "/assets/images/thumbnails/standards.png"
    alt: "Standards"
    title: "Standards"
    excerpt: "What standards need to be in place for ML Sensors?"

  - image_path: "/assets/images/thumbnails/ethics.png"
    alt: "Ethics"
    title: "Ethics"
    excerpt: "What ethical considerations are needed for ML Sensors?"

---

Machine learning sensors represent a paradigm shift for the future of embedded machine learning applications. Current instantiations of embedded ML suffer from complex integration, lack of modularity, and privacy and security concerns from data movement. ML sensors provide a more data-centric paradigm for embedding sensor intelligence on edge devices to combat these challenges.

Our vision for ''sensor 2.0'' entails segregating sensor input data and ML processing from the wider system at the hardware level and providing a thin interface that mimics traditional sensors in functionality. This separation leads to a modular and easy-to-use ML sensor device. ML sensors increase privacy and accuracy while making it easier for system builders to integrate ML into their products as a simple component.

To learn more about our approach, check out our [whitepaper on arXiv](https://arxiv.org/abs/2206.03266).

{% include section_break %}
# Challenges
{% include feature_row id="challenges" max_height="200px" %}

{% include section_break %}
# Call for Working Group Members
**We are actively growing our working group. If you would like to be a part of it please email us at:<br/>[ml-sensors@googlegroups.com](mailto:ml-sensors@googlegroups.com)!**


{% include section_break %}
# Example ML Sensor Datasheet

This illustrative example datasheet highlighting the various sections of an ML Sensor datasheet. On the top, we have the items currently found in standard datasheets: the description, features, use cases, diagrams and form factor, hardware characteristics, and communication specification and pinout. On the bottom, we have the new items that need to be included in an ML sensor datasheet: the ML model characteristics, dataset nutrition label, environmental impact analysis, and end-to-end performance analysis. While we compressed this datasheet into a one-page illustrative example by combining features and data from a mixture of sources, on a real datasheet, we assume each of these sections would be longer and include additional explanatory text to increase the transparency of the device to end-users. Interested users can find the most up-to-date version of the datasheet online at [https://github.com/harvard-edge/ML-Sensors](https://github.com/harvard-edge/ML-Sensors).

![Example ML Sensor Datasheet](/assets/images/example_datasheet.png)

{% include section_break %}
# Thanks to our lead supporters:
{% include gallery id="supporters" max_height="200px" %}
{% include section_break %}